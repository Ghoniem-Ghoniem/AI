{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.51743</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.14</td>\n",
       "      <td>73.09</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.51756</td>\n",
       "      <td>13.15</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.05</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.51918</td>\n",
       "      <td>14.04</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>72.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.51755</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.51571</td>\n",
       "      <td>12.72</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.56</td>\n",
       "      <td>73.20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>8.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.51763</td>\n",
       "      <td>12.80</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.27</td>\n",
       "      <td>73.01</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.51589</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.40</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.69</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.51748</td>\n",
       "      <td>12.86</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.27</td>\n",
       "      <td>73.21</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.51763</td>\n",
       "      <td>12.61</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.31</td>\n",
       "      <td>73.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>12.81</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.23</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.51784</td>\n",
       "      <td>12.68</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1.16</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.52196</td>\n",
       "      <td>14.36</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>71.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.51911</td>\n",
       "      <td>13.90</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.18</td>\n",
       "      <td>72.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.51735</td>\n",
       "      <td>13.02</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.69</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.51750</td>\n",
       "      <td>12.82</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.49</td>\n",
       "      <td>72.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51736</td>\n",
       "      <td>12.78</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.79</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.51751</td>\n",
       "      <td>12.81</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.35</td>\n",
       "      <td>73.02</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.51720</td>\n",
       "      <td>13.38</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>72.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.51764</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.21</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.51793</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.41</td>\n",
       "      <td>72.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.51721</td>\n",
       "      <td>12.87</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.33</td>\n",
       "      <td>73.04</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.51768</td>\n",
       "      <td>12.56</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.43</td>\n",
       "      <td>73.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.51784</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.28</td>\n",
       "      <td>72.86</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51131</td>\n",
       "      <td>13.69</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.81</td>\n",
       "      <td>72.81</td>\n",
       "      <td>1.76</td>\n",
       "      <td>5.43</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.51838</td>\n",
       "      <td>14.32</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.22</td>\n",
       "      <td>71.25</td>\n",
       "      <td>1.46</td>\n",
       "      <td>5.79</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.52315</td>\n",
       "      <td>13.44</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.23</td>\n",
       "      <td>72.38</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.52247</td>\n",
       "      <td>14.86</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.06</td>\n",
       "      <td>70.26</td>\n",
       "      <td>0.76</td>\n",
       "      <td>9.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.52365</td>\n",
       "      <td>15.79</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.31</td>\n",
       "      <td>70.43</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.51613</td>\n",
       "      <td>13.88</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.79</td>\n",
       "      <td>73.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.51602</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.76</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>73.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.51719</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>73.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.53</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.08</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.51683</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.98</td>\n",
       "      <td>73.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.52</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.51545</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.68</td>\n",
       "      <td>73.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.07</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.51556</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.54</td>\n",
       "      <td>73.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9.41</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.51727</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.51531</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.66</td>\n",
       "      <td>73.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.51609</td>\n",
       "      <td>15.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.51</td>\n",
       "      <td>73.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.51508</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>73.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.34</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.51653</td>\n",
       "      <td>11.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>75.18</td>\n",
       "      <td>2.70</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.51514</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>73.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.51658</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1.51617</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>73.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1.51732</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1.51645</td>\n",
       "      <td>14.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.87</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1.51831</td>\n",
       "      <td>14.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.82</td>\n",
       "      <td>72.86</td>\n",
       "      <td>1.41</td>\n",
       "      <td>6.47</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1.51640</td>\n",
       "      <td>14.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.74</td>\n",
       "      <td>72.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba    Fe  Type\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.00     1\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.00     1\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.00     1\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.00     1\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.00     1\n",
       "5    1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.00  0.26     1\n",
       "6    1.51743  13.30  3.60  1.14  73.09  0.58  8.17  0.00  0.00     1\n",
       "7    1.51756  13.15  3.61  1.05  73.24  0.57  8.24  0.00  0.00     1\n",
       "8    1.51918  14.04  3.58  1.37  72.08  0.56  8.30  0.00  0.00     1\n",
       "9    1.51755  13.00  3.60  1.36  72.99  0.57  8.40  0.00  0.11     1\n",
       "10   1.51571  12.72  3.46  1.56  73.20  0.67  8.09  0.00  0.24     1\n",
       "11   1.51763  12.80  3.66  1.27  73.01  0.60  8.56  0.00  0.00     1\n",
       "12   1.51589  12.88  3.43  1.40  73.28  0.69  8.05  0.00  0.24     1\n",
       "13   1.51748  12.86  3.56  1.27  73.21  0.54  8.38  0.00  0.17     1\n",
       "14   1.51763  12.61  3.59  1.31  73.29  0.58  8.50  0.00  0.00     1\n",
       "15   1.51761  12.81  3.54  1.23  73.24  0.58  8.39  0.00  0.00     1\n",
       "16   1.51784  12.68  3.67  1.16  73.11  0.61  8.70  0.00  0.00     1\n",
       "17   1.52196  14.36  3.85  0.89  71.36  0.15  9.15  0.00  0.00     1\n",
       "18   1.51911  13.90  3.73  1.18  72.12  0.06  8.89  0.00  0.00     1\n",
       "19   1.51735  13.02  3.54  1.69  72.73  0.54  8.44  0.00  0.07     1\n",
       "20   1.51750  12.82  3.55  1.49  72.75  0.54  8.52  0.00  0.19     1\n",
       "21   1.51966  14.77  3.75  0.29  72.02  0.03  9.00  0.00  0.00     1\n",
       "22   1.51736  12.78  3.62  1.29  72.79  0.59  8.70  0.00  0.00     1\n",
       "23   1.51751  12.81  3.57  1.35  73.02  0.62  8.59  0.00  0.00     1\n",
       "24   1.51720  13.38  3.50  1.15  72.85  0.50  8.43  0.00  0.00     1\n",
       "25   1.51764  12.98  3.54  1.21  73.00  0.65  8.53  0.00  0.00     1\n",
       "26   1.51793  13.21  3.48  1.41  72.64  0.59  8.43  0.00  0.00     1\n",
       "27   1.51721  12.87  3.48  1.33  73.04  0.56  8.43  0.00  0.00     1\n",
       "28   1.51768  12.56  3.52  1.43  73.15  0.57  8.54  0.00  0.00     1\n",
       "29   1.51784  13.08  3.49  1.28  72.86  0.60  8.49  0.00  0.00     1\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...   ...   ...\n",
       "184  1.51115  17.38  0.00  0.34  75.41  0.00  6.65  0.00  0.00     6\n",
       "185  1.51131  13.69  3.20  1.81  72.81  1.76  5.43  1.19  0.00     7\n",
       "186  1.51838  14.32  3.26  2.22  71.25  1.46  5.79  1.63  0.00     7\n",
       "187  1.52315  13.44  3.34  1.23  72.38  0.60  8.83  0.00  0.00     7\n",
       "188  1.52247  14.86  2.20  2.06  70.26  0.76  9.76  0.00  0.00     7\n",
       "189  1.52365  15.79  1.83  1.31  70.43  0.31  8.61  1.68  0.00     7\n",
       "190  1.51613  13.88  1.78  1.79  73.10  0.00  8.67  0.76  0.00     7\n",
       "191  1.51602  14.85  0.00  2.38  73.28  0.00  8.76  0.64  0.09     7\n",
       "192  1.51623  14.20  0.00  2.79  73.46  0.04  9.04  0.40  0.09     7\n",
       "193  1.51719  14.75  0.00  2.00  73.02  0.00  8.53  1.59  0.08     7\n",
       "194  1.51683  14.56  0.00  1.98  73.29  0.00  8.52  1.57  0.07     7\n",
       "195  1.51545  14.14  0.00  2.68  73.39  0.08  9.07  0.61  0.05     7\n",
       "196  1.51556  13.87  0.00  2.54  73.23  0.14  9.41  0.81  0.01     7\n",
       "197  1.51727  14.70  0.00  2.34  73.28  0.00  8.95  0.66  0.00     7\n",
       "198  1.51531  14.38  0.00  2.66  73.10  0.04  9.08  0.64  0.00     7\n",
       "199  1.51609  15.01  0.00  2.51  73.05  0.05  8.83  0.53  0.00     7\n",
       "200  1.51508  15.15  0.00  2.25  73.50  0.00  8.34  0.63  0.00     7\n",
       "201  1.51653  11.95  0.00  1.19  75.18  2.70  8.93  0.00  0.00     7\n",
       "202  1.51514  14.85  0.00  2.42  73.72  0.00  8.39  0.56  0.00     7\n",
       "203  1.51658  14.80  0.00  1.99  73.11  0.00  8.28  1.71  0.00     7\n",
       "204  1.51617  14.95  0.00  2.27  73.30  0.00  8.71  0.67  0.00     7\n",
       "205  1.51732  14.95  0.00  1.80  72.99  0.00  8.61  1.55  0.00     7\n",
       "206  1.51645  14.94  0.00  1.87  73.11  0.00  8.67  1.38  0.00     7\n",
       "207  1.51831  14.39  0.00  1.82  72.86  1.41  6.47  2.88  0.00     7\n",
       "208  1.51640  14.37  0.00  2.74  72.85  0.00  9.45  0.54  0.00     7\n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.00     7\n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.00     7\n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.00     7\n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.00     7\n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.00     7\n",
       "\n",
       "[214 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics as m\n",
    "df = pd.read_csv(\"glass.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.191885</td>\n",
       "      <td>-0.122274</td>\n",
       "      <td>-0.407326</td>\n",
       "      <td>-0.542052</td>\n",
       "      <td>-0.289833</td>\n",
       "      <td>0.810403</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.143010</td>\n",
       "      <td>-0.164237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Na</th>\n",
       "      <td>-0.191885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.273732</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>-0.069809</td>\n",
       "      <td>-0.266087</td>\n",
       "      <td>-0.275442</td>\n",
       "      <td>0.326603</td>\n",
       "      <td>-0.241346</td>\n",
       "      <td>0.502898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mg</th>\n",
       "      <td>-0.122274</td>\n",
       "      <td>-0.273732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.481799</td>\n",
       "      <td>-0.165927</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>-0.443750</td>\n",
       "      <td>-0.492262</td>\n",
       "      <td>0.083060</td>\n",
       "      <td>-0.744993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Al</th>\n",
       "      <td>-0.407326</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>-0.481799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005524</td>\n",
       "      <td>0.325958</td>\n",
       "      <td>-0.259592</td>\n",
       "      <td>0.479404</td>\n",
       "      <td>-0.074402</td>\n",
       "      <td>0.598829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>-0.542052</td>\n",
       "      <td>-0.069809</td>\n",
       "      <td>-0.165927</td>\n",
       "      <td>-0.005524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.193331</td>\n",
       "      <td>-0.208732</td>\n",
       "      <td>-0.102151</td>\n",
       "      <td>-0.094201</td>\n",
       "      <td>0.151565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>-0.289833</td>\n",
       "      <td>-0.266087</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.325958</td>\n",
       "      <td>-0.193331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.317836</td>\n",
       "      <td>-0.042618</td>\n",
       "      <td>-0.007719</td>\n",
       "      <td>-0.010054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca</th>\n",
       "      <td>0.810403</td>\n",
       "      <td>-0.275442</td>\n",
       "      <td>-0.443750</td>\n",
       "      <td>-0.259592</td>\n",
       "      <td>-0.208732</td>\n",
       "      <td>-0.317836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.112841</td>\n",
       "      <td>0.124968</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ba</th>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.326603</td>\n",
       "      <td>-0.492262</td>\n",
       "      <td>0.479404</td>\n",
       "      <td>-0.102151</td>\n",
       "      <td>-0.042618</td>\n",
       "      <td>-0.112841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058692</td>\n",
       "      <td>0.575161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fe</th>\n",
       "      <td>0.143010</td>\n",
       "      <td>-0.241346</td>\n",
       "      <td>0.083060</td>\n",
       "      <td>-0.074402</td>\n",
       "      <td>-0.094201</td>\n",
       "      <td>-0.007719</td>\n",
       "      <td>0.124968</td>\n",
       "      <td>-0.058692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.188278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>-0.164237</td>\n",
       "      <td>0.502898</td>\n",
       "      <td>-0.744993</td>\n",
       "      <td>0.598829</td>\n",
       "      <td>0.151565</td>\n",
       "      <td>-0.010054</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.575161</td>\n",
       "      <td>-0.188278</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RI        Na        Mg        Al        Si         K        Ca  \\\n",
       "RI    1.000000 -0.191885 -0.122274 -0.407326 -0.542052 -0.289833  0.810403   \n",
       "Na   -0.191885  1.000000 -0.273732  0.156794 -0.069809 -0.266087 -0.275442   \n",
       "Mg   -0.122274 -0.273732  1.000000 -0.481799 -0.165927  0.005396 -0.443750   \n",
       "Al   -0.407326  0.156794 -0.481799  1.000000 -0.005524  0.325958 -0.259592   \n",
       "Si   -0.542052 -0.069809 -0.165927 -0.005524  1.000000 -0.193331 -0.208732   \n",
       "K    -0.289833 -0.266087  0.005396  0.325958 -0.193331  1.000000 -0.317836   \n",
       "Ca    0.810403 -0.275442 -0.443750 -0.259592 -0.208732 -0.317836  1.000000   \n",
       "Ba   -0.000386  0.326603 -0.492262  0.479404 -0.102151 -0.042618 -0.112841   \n",
       "Fe    0.143010 -0.241346  0.083060 -0.074402 -0.094201 -0.007719  0.124968   \n",
       "Type -0.164237  0.502898 -0.744993  0.598829  0.151565 -0.010054  0.000952   \n",
       "\n",
       "            Ba        Fe      Type  \n",
       "RI   -0.000386  0.143010 -0.164237  \n",
       "Na    0.326603 -0.241346  0.502898  \n",
       "Mg   -0.492262  0.083060 -0.744993  \n",
       "Al    0.479404 -0.074402  0.598829  \n",
       "Si   -0.102151 -0.094201  0.151565  \n",
       "K    -0.042618 -0.007719 -0.010054  \n",
       "Ca   -0.112841  0.124968  0.000952  \n",
       "Ba    1.000000 -0.058692  0.575161  \n",
       "Fe   -0.058692  1.000000 -0.188278  \n",
       "Type  0.575161 -0.188278  1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "X = df[['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe']]\n",
    "y = df[['Type']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Classifier = LogisticRegression()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[2]\n",
      "0.3546511627906977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "Classifier = SVC()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[1]\n",
      "0.43023255813953487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "Classifier = LinearSVC()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1059: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2]\n",
      "0.6111111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "Classifier = RidgeClassifier()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2]\n",
      "0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "Classifier = KNeighborsClassifier()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2]\n",
      "0.5185185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "Classifier = MLPClassifier()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[5]\n",
      "0.35185185185185186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes  import GaussianNB\n",
    "Classifier = GaussianNB()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[6]\n",
      "0.5370370370370371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes  import MultinomialNB\n",
    "Classifier = MultinomialNB()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2]\n",
      "0.42592592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but BernoulliNB was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but BernoulliNB was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes  import BernoulliNB\n",
    "Classifier = BernoulliNB()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[2]\n",
      "0.3546511627906977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "Classifier = SGDClassifier()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[2]\n",
      "0.6569767441860465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "Classifier = DecisionTreeClassifier()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "0.6802325581395349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "Classifier = RandomForestClassifier()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "0.6453488372093024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  \n",
    "Classifier = GradientBoostingClassifier()\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = Classifier.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =Classifier.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=15.\n",
      "  UserWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[2]\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier #Stacking regressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import LinearSVC \n",
    "\n",
    "\n",
    "estimators = [('dtregressor', DecisionTreeClassifier()),\n",
    "('svr', LinearSVC(random_state=42))]\n",
    "stackingCLS = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(n_estimators=10,random_state=42))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "stackingCLS.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "score = cross_val_score(stackingCLS,X,y,cv = 15,scoring = 'r2')\n",
    "\n",
    "y_predict = stackingCLS.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,0]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict = stackingCLS.predict([[1.52101,13.64,4.49,1.1,71.78,0.06,8.75,0,20]]) \n",
    "print (y_predict)#prediction for 2020\n",
    "y_predict =stackingCLS.predict(X_test)  #Get the splitted part for testing to be predicted, and check the accuray\n",
    "print(m.accuracy_score(y_test, y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
