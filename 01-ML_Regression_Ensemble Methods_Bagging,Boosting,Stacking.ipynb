{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice      5891\n",
      "BuildingAge    5891\n",
      "Area           5891\n",
      "Floor          5891\n",
      "Location       5891\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"real_estate_data.xlsx\",'Real_Estate_data')\n",
    "print (df.count())\n",
    "SVMdf = df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['BuildingAge','Area','Floor']]\n",
    "y = df[['SalePrice']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline the linear regression to compare with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54326.14126485]]\n",
      "Mean Absolute Error (MAE): 48602.85374996157\n",
      "Explained Variance Score: 0.6826363343970234\n",
      "Median Absolute Error: 43612.62988384161\n",
      "R^2: 0.6826218632935481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\n",
    "\n",
    "LRRegressor = LinearRegression() #gives less accuracy R^2: 0.6826995509387148\n",
    "\n",
    "LRRegressor.fit(X_train, y_train)\n",
    "print (LRRegressor.predict([[1995,280,10]]))#prediction for apartment, with building age 1995, area 280, and floor 10#Model Evaluation\n",
    "from sklearn import metrics\n",
    "y_pred = LRRegressor.predict(X_test)\n",
    "#Model Evaluation\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))\n",
    "#print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_test, y_pred))\n",
    "#print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_test, y_pred)) #Check the accuracty when changing the sample size, when getting negative value, \n",
    "#R2 is negative only when the chosen model does not follow the trend of the data. It seems that your model may be giving better performance because of over-fitting. It can be a case of over-fitting in the model. It can happen because of various reasons like small dataset and noise in the dataset.Jun 13, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Methods : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79710.00666667]\n",
      "Mean Absolute Error (MAE): 37885.40006951715\n",
      "Mean Squared Error (MSE): 2471744040.231281\n",
      "Explained Variance Score: 0.782261036163278\n",
      "Mean Squared Log Error: 0.06755223513962008\n",
      "Median Absolute Error: 29379.899999999994\n",
      "R^2: 0.7816410213463889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "#ensemble regression\n",
    "from sklearn.ensemble import RandomForestRegressor  #bagging technique\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=0)\n",
    "RFregressor = RandomForestRegressor(n_estimators = 10)\n",
    "RFregressor.fit(X_train, y_train)\n",
    "print (RFregressor.predict([[1995,280,10]]))#prediction for apartment, with building age 1995, area 280, and floor 10#Model Evaluation\n",
    "y_pred = RFregressor.predict(X_test)\n",
    "#Model Evaluation\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_test, y_pred))\n",
    "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_test, y_pred)) #Check the accuracty when changing the sample size, when getting negative value, \n",
    "#R2 is negative only when the chosen model does not follow the trend of the data. It seems that your model may be giving better performance because of over-fitting. It can be a case of over-fitting in the model. It can happen because of various reasons like small dataset and noise in the dataset.Jun 13, 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60080.49666667]\n",
      "Mean Absolute Error (MAE): 38083.92974165818\n",
      "Mean Squared Error (MSE): 2515696734.9060144\n",
      "Explained Variance Score: 0.7779459189490293\n",
      "Mean Squared Log Error: 0.06905898539287264\n",
      "Median Absolute Error: 30265.849999999977\n",
      "R^2: 0.777758149430027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:429: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but BaggingRegressor was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "#ensemble regression\n",
    "from sklearn.ensemble import BaggingRegressor  #bagging technique\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=0)\n",
    "baggingregressor = BaggingRegressor(n_estimators = 10) #estimators means no. trees , max depth of the tree\n",
    "baggingregressor.fit(X_train, y_train)\n",
    "print (baggingregressor.predict([[1995,280,10]]))#prediction for apartment, with building age 1995, area 280, and floor 10#Model Evaluation\n",
    "y_pred = baggingregressor.predict(X_test)\n",
    "#Model Evaluation\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_test, y_pred))\n",
    "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_test, y_pred)) #Check the accuracty when changing the sample size, when getting negative value, \n",
    "#R2 is negative only when the chosen model does not follow the trend of the data. It seems that your model may be giving better performance because of over-fitting. It can be a case of over-fitting in the model. It can happen because of various reasons like small dataset and noise in the dataset.Jun 13, 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Methods : Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58822.56109666]\n",
      "Mean Absolute Error (MAE): 35506.470869020224\n",
      "Mean Squared Error (MSE): 1967472719.5439093\n",
      "Explained Variance Score: 0.825422239537838\n",
      "Mean Squared Log Error: 0.053889399171574114\n",
      "Median Absolute Error: 29933.126897092778\n",
      "R^2: 0.8253199316808022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "#ensemble regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor # boosting technique\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.65, random_state=0)\n",
    "GBregressor = GradientBoostingRegressor()\n",
    "GBregressor.fit(X_train, y_train)\n",
    "print (GBregressor.predict([[1995,280,10]]))#prediction for apartment, with building age 1995, area 280, and floor 10#Model Evaluation\n",
    "y_pred = GBregressor.predict(X_test)\n",
    "#Model Evaluation\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_test, y_pred))\n",
    "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_test, y_pred)) #Check the accuracty when changing the sample size, when getting negative value, \n",
    "#R2 is negative only when the chosen model does not follow the trend of the data. It seems that your model may be giving better performance because of over-fitting. It can be a case of over-fitting in the model. It can happen because of various reasons like small dataset and noise in the dataset.Jun 13, 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of is: 0.7272646677205148\n",
      "[77379.72991328]\n",
      "Mean Absolute Error (MAE): 37848.41523270104\n",
      "Mean Squared Error (MSE): 2261232783.537604\n",
      "Explained Variance Score: 0.794073128533801\n",
      "Mean Squared Log Error: 0.06165003861092783\n",
      "Median Absolute Error: 32599.50908798295\n",
      "R^2: 0.7940560167800669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor #Stacking regressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.svm import LinearSVR \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "estimators = [('Decision tree', DecisionTreeRegressor()),\n",
    "('Random Forest', RandomForestRegressor()),\n",
    "('SVR', LinearSVR(random_state=42))              \n",
    "             ]\n",
    "\n",
    "stackingreg = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "stackingreg.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "score = cross_val_score(stackingreg,X,y,cv = 15,scoring = 'r2')\n",
    "print(\"The accuracy score of is:\",score.mean())\n",
    "print (stackingreg.predict([[1995,280,10]]))#prediction for apartment, with building age 1995, area 280, and floor 10#Model Evaluation\n",
    "y_pred = stackingreg.predict(X_test)\n",
    "#Model Evaluation\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_test, y_pred))\n",
    "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_test, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_test, y_pred)) #Check the accuracty when changing the sample size, when getting negative value, \n",
    "#R2 is negative only when the chosen model does not follow the trend of the data. It seems that your model may be giving better performance because of over-fitting. It can be a case of over-fitting in the model. It can happen because of various reasons like small dataset and noise in the dataset.Jun 13, 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the model: Decision tree [0.58001691 0.44655556 0.19187333 0.59669884 0.16879598]\n",
      "Score of the model: Random Forest [0.58001691 0.44655556 0.19187333 0.59669884 0.16879598]\n",
      "Score of the model: SVR [0.58001691 0.44655556 0.19187333 0.59669884 0.16879598]\n"
     ]
    }
   ],
   "source": [
    "#validating the stack results\n",
    "for name, model in estimators:\n",
    "    cross_val_score(model, X, y, scoring='r2')\n",
    "    print('Score of the model:' ,name, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
